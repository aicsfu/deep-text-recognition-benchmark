import os
import time
from PIL import Image
import torch
from model import Model
from utils import CTCLabelConverter, AttnLabelConverter
from dataset import AlignCollate

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# üîß –ù–ê–°–¢–†–û–ô–ö–ò
image_path = r"C:\A\a2\images"  # –ü–ê–ü–ö–ê —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
saved_model = r"C:\best_accuracy.pth"

Transformation = "TPS"
FeatureExtraction = "ResNet"
SequenceModeling = "BiLSTM"
Prediction = "Attn"

character = " !%'()*+,-./0123456789:;<=>[]^_v{|}~¬ß¬´¬ª–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—ñ—£—≥—µ‚Ññ"
batch_max_length = 25
imgH = 128
imgW = 512
input_channel = 1
output_channel = 512
hidden_size = 256
rgb = False
PAD = True


# ==== –ö–û–ù–§–ò–ì ====
class Opt:
    pass


opt = Opt()
opt.Transformation = Transformation
opt.FeatureExtraction = FeatureExtraction
opt.SequenceModeling = SequenceModeling
opt.Prediction = Prediction
opt.character = character
opt.batch_max_length = batch_max_length
opt.imgH = imgH
opt.imgW = imgW
opt.input_channel = 3 if rgb else 1
opt.output_channel = output_channel
opt.hidden_size = hidden_size
opt.saved_model = saved_model
opt.rgb = rgb
opt.PAD = PAD
opt.num_fiducial = 20
opt.num_class = len(character)
opt.sensitive = False
opt.data_filtering_off = True


def load_model(opt):
    if "CTC" in opt.Prediction:
        converter = CTCLabelConverter(opt.character)
    else:
        converter = AttnLabelConverter(opt.character)
    opt.num_class = len(converter.character)

    model = Model(opt)
    model = torch.nn.DataParallel(model).to(device)

    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {opt.saved_model}")
    state_dict = torch.load(opt.saved_model, map_location=device)
    if "module" in list(state_dict.keys())[0]:
        model.load_state_dict(state_dict)
    else:
        model.load_state_dict({"module." + k: v for k, v in state_dict.items()})

    model = model.module
    model.eval()
    return model, converter


def preprocess_image(image_path, opt):
    img = Image.open(image_path).convert("RGB" if opt.rgb else "L")
    AlignCollate_infer = AlignCollate(
        imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD
    )
    image_tensor, _ = AlignCollate_infer([(img, "")])
    return image_tensor.to(device)


def predict(model, converter, image, opt):
    batch_size = image.size(0)
    length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)
    text_for_pred = (
        torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)
    )

    with torch.no_grad():
        if "CTC" in opt.Prediction:
            preds = model(image, text_for_pred)
            preds_size = torch.IntTensor([preds.size(1)] * batch_size)
            _, preds_index = preds.max(2)
            preds_str = converter.decode(preds_index, preds_size)
        else:
            preds = model(image, text_for_pred, is_train=False)
            _, preds_index = preds.max(2)
            preds_str = converter.decode(preds_index, length_for_pred)
            preds_str = [s.split("[s]")[0] for s in preds_str]

    return preds_str[0]


def infer(opt, image_path):
    model, converter = load_model(opt)

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if os.path.isdir(image_path):
        image_files = sorted(
            [
                os.path.join(image_path, f)
                for f in os.listdir(image_path)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]
        )
    else:
        image_files = [image_path]

    if not image_files:
        print("‚ùå –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    total_time = 0
    total_images = len(image_files)

    print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n")

    for img_path in image_files:
        image_tensor = preprocess_image(img_path, opt)

        start_time = time.time()
        prediction = predict(model, converter, image_tensor, opt)
        end_time = time.time()

        duration = end_time - start_time
        total_time += duration

        print(
            f"{os.path.basename(img_path):<30} ‚Üí {prediction:<30} ({duration * 1000:.2f} ms)"
        )

    avg_time = total_time / total_images
    print("\n" + "=" * 60)
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {avg_time * 1000:.2f} ms")
    print("=" * 60)


# üöÄ –°—Ç–∞—Ä—Ç
if __name__ == "__main__":
    infer(opt, image_path)
