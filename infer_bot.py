import os
import shutil
import time
import cv2
import numpy as np
from PIL import Image
import torch
import easyocr
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, ContextTypes, filters
import nest_asyncio
import asyncio
import pandas as pd
import base64
import mimetypes
import json

# –ü—Ä–∏–º–µ–Ω—è–µ–º nest_asyncio, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ "Cannot close a running event loop"
nest_asyncio.apply()

# === CONFIG ===
BOT_TOKEN = (
    "7287622548:AAGBEwjd5nhQS-XhGv4sa6Ihc06LOfZlHM4"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π —Ä–µ–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω
)


# –ú–æ–¥–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ (–∏–∑ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã)
class Opt:
    pass


opt = Opt()
opt.Transformation = "TPS"
opt.FeatureExtraction = "ResNet"
opt.SequenceModeling = "BiLSTM"
opt.Prediction = "Attn"
opt.character = " !%'()*+,-./0123456789:;<=>[]^_v{|}~¬ß¬´¬ª–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—ñ—£—≥—µ‚Ññ"
opt.batch_max_length = 25
opt.imgH = 128
opt.imgW = 512
opt.input_channel = 1  # –ï—Å–ª–∏ rgb=False, —Ç–æ 1; –∏–Ω–∞—á–µ 3
opt.output_channel = 512
opt.hidden_size = 256
opt.rgb = False
opt.PAD = True
opt.num_fiducial = 20
opt.num_class = len(opt.character)
opt.sensitive = False
opt.data_filtering_off = True
opt.saved_model = r"C:\best_accuracy.pth"  # –ü—É—Ç—å –∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–µ–∑–∫–æ–≤ (crops) ‚Äî —Å–æ–∑–¥–∞—ë—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –æ—á–∏—â–∞–µ—Ç—Å—è –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
CROPS_DIR = os.path.join(os.getcwd(), "crops")
if os.path.exists(CROPS_DIR):
    shutil.rmtree(CROPS_DIR)
os.makedirs(CROPS_DIR, exist_ok=True)


# ==== –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64 HTML (–¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É) ====
def image_to_base64_html(image_path, max_width=200):
    if not os.path.exists(image_path):
        return ""
    with open(image_path, "rb") as img_file:
        img_data = img_file.read()
    mime_type, _ = mimetypes.guess_type(image_path)
    if mime_type is None:
        mime_type = "image/png"
    b64_data = base64.b64encode(img_data).decode("utf-8")
    return f'<img src="data:{mime_type};base64,{b64_data}" style="max-width: {max_width}px;"/>'


# ==== –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ====
def load_model(opt):
    from model import Model
    from utils import CTCLabelConverter, AttnLabelConverter

    print("[DEBUG] –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
    # –î–ª—è –º–æ–¥–µ–ª–∏ Attn –∏—Å–ø–æ–ª—å–∑—É–µ–º AttnLabelConverter
    converter = AttnLabelConverter(opt.character)
    opt.num_class = len(converter.character)

    model = Model(opt)
    model = torch.nn.DataParallel(model).to(device)
    state_dict = torch.load(opt.saved_model, map_location=device)
    print("[DEBUG] –ó–∞–≥—Ä—É–∑–∫–∞ state_dict –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    if "module" in list(state_dict.keys())[0]:
        model.load_state_dict(state_dict)
    else:
        model.load_state_dict({"module." + k: v for k, v in state_dict.items()})
    model = model.module
    model.eval()
    print("[DEBUG] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ eval mode")
    return model, converter


# ==== –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ AlignCollate (–∏–∑ PIL Image) ====
def preprocess_image_from_pil(pil_img, opt):
    from dataset import AlignCollate

    print("[DEBUG] –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ AlignCollate...")
    align = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)
    image_tensor, _ = align([(pil_img.convert("RGB" if opt.rgb else "L"), "")])
    print(f"[DEBUG] –¢–µ–Ω–∑–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_tensor.shape}")
    return image_tensor.to(device)


# ==== –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –±–ª–æ–∫–µ ====
def predict(model, converter, image_tensor, opt):
    print("[DEBUG] –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    batch_size = image_tensor.size(0)
    length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)
    text_for_pred = (
        torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)
    )
    with torch.no_grad():
        preds = model(image_tensor, text_for_pred, is_train=False)
        _, preds_index = preds.max(2)
        preds_str = converter.decode(preds_index, length_for_pred)
        preds_str = [s.split("[s]")[0] for s in preds_str]
    recognized = preds_str[0]
    print("[DEBUG] –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    return recognized


# ==== –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ª–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (—Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏) ====
def process_full_image(image_path, opt, crops_dir):
    model, converter = load_model(opt)
    reader = easyocr.Reader(["ru", "en"], gpu=torch.cuda.is_available())
    print("[DEBUG] –°—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ª–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ OpenCV...")
    image = cv2.imread(image_path)

    # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ (EasyOCR)
    start_detection = time.time()
    detections = reader.readtext(image)
    detection_time = time.time() - start_detection
    print(
        f"[DEBUG] –ù–∞–π–¥–µ–Ω–æ {len(detections)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤. –í—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_time:.2f} —Å–µ–∫."
    )

    crop_results = []  # –î–ª—è HTML-–æ—Ç—á—ë—Ç–∞ (thumbnail + prediction)
    annotations_list = []  # –î–ª—è COCO-–ø–æ–¥–æ–±–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏
    total_recognition_time = 0

    for i, (bbox, _, confidence) in enumerate(detections):
        pts = np.array(bbox).astype(int)
        x, y, w, h = cv2.boundingRect(pts)
        cropped_img = image[y : y + h, x : x + w]

        crop_path = os.path.join(crops_dir, f"word_{i:03}.png")
        cv2.imwrite(crop_path, cropped_img)
        print(f"[DEBUG] –°–æ—Ö—Ä–∞–Ω—ë–Ω crop {crop_path}")

        pil_crop = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
        image_tensor_crop = preprocess_image_from_pil(pil_crop, opt)

        start_recognition = time.time()
        prediction = predict(model, converter, image_tensor_crop, opt)
        recognition_time = time.time() - start_recognition
        total_recognition_time += recognition_time

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è HTML-–æ—Ç—á—ë—Ç–∞
        crop_results.append(
            {
                "thumbnail": image_to_base64_html(crop_path, max_width=150),
                "prediction": prediction,
            }
        )
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è COCO-–ø–æ–¥–æ–±–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ (bbox –≤ —Ñ–æ—Ä–º–∞—Ç–µ [x, y, w, h])
        annotation = {
            "id": i,
            "bbox": [int(x), int(y), int(w), int(h)],
            "text": prediction,
        }
        annotations_list.append(annotation)

        print(f"[{i:03}] ‚Üí {prediction} ({recognition_time*1000:.2f} –º—Å)")

    final_text = " ".join([item["prediction"] for item in crop_results])
    print("\nüìú –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(final_text)
    print(f"\n‚è± –í—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_time:.2f} —Å–µ–∫")
    print(
        f"‚è± –°—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –±–ª–æ–∫–æ–≤: {total_recognition_time*1000:.2f} –º—Å"
    )

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML-—Ç–∞–±–ª–∏—Ü—ã —Å –æ–±—Ä–µ–∑–∫–∞–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    df_html = pd.DataFrame(crop_results, columns=["thumbnail", "prediction"])
    table_html = df_html.to_html(escape=False, index=False)

    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π HTML-–¥–æ–∫—É–º–µ–Ω—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏ UTF-8
    full_html = f"""<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>–û—Ç—á—ë—Ç OCR</title>
  </head>
  <body>
    {table_html}
  </body>
</html>
"""

    html_path = os.path.join(os.getcwd(), "results.html")
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(full_html)
    print(f"[DEBUG] HTML-–æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {html_path}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è COCO-–ø–æ–¥–æ–±–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ –≤ –≤–∏–¥–µ JSON-—Å–ª–æ–≤–∞—Ä—è
    coco_annotations = {"annotations": annotations_list}
    json_path = os.path.join(os.getcwd(), "results.json")
    with open(json_path, "w", encoding="utf-8") as json_file:
        json.dump(coco_annotations, json_file, ensure_ascii=False, indent=4)
    print(f"[DEBUG] COCO JSON —Ä–∞–∑–º–µ—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {json_path}")

    return (
        final_text,
        crop_results,
        detection_time,
        total_recognition_time,
        html_path,
        json_path,
    )


# ==== –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Ñ–æ—Ç–æ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Ñ–∞–π–ª–æ–≤) –≤ Telegram –±–æ—Ç–µ ====
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    print("[DEBUG] –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–æ—Ç–æ")
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    local_path = os.path.join(os.getcwd(), "received.jpg")
    print(f"[DEBUG] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ –≤ {local_path}...")
    await file.download_to_drive(local_path)
    print("[DEBUG] –§–æ—Ç–æ —Å–∫–∞—á–∞–Ω–æ")

    start = time.time()
    (
        final_text,
        crop_results,
        detection_time,
        total_recognition_time,
        html_path,
        json_path,
    ) = process_full_image(local_path, opt, CROPS_DIR)
    total_duration = time.time() - start

    reply = (
        f"üìú –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{final_text}\n\n"
        f"‚è± –í—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_time:.2f} —Å–µ–∫\n"
        f"‚è± –°—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {total_recognition_time*1000:.2f} –º—Å\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_duration:.2f} —Å–µ–∫"
    )
    print(f"[DEBUG] –û—Ç–≤–µ—Ç: {reply}")
    await update.message.reply_text(reply)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º HTML-–æ—Ç—á—ë—Ç –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
    with open(html_path, "rb") as html_file:
        await update.message.reply_document(document=html_file, filename="results.html")
    print("[DEBUG] HTML-–æ—Ç—á—ë—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º JSON —Å COCO-—Ä–∞–∑–º–µ—Ç–∫–æ–π –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
    with open(json_path, "rb") as json_file:
        await update.message.reply_document(document=json_file, filename="results.json")
    print("[DEBUG] JSON —Ä–∞–∑–º–µ—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.")


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    document = update.message.document
    if not document.mime_type.startswith("image/"):
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º."
        )
        return

    print("[DEBUG] –ü–æ–ª—É—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
    file = await context.bot.get_file(document.file_id)
    local_path = os.path.join(os.getcwd(), "received.jpg")
    print(f"[DEBUG] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ {local_path}...")
    await file.download_to_drive(local_path)
    print("[DEBUG] –î–æ–∫—É–º–µ–Ω—Ç —Å–∫–∞—á–∞–Ω")

    start = time.time()
    (
        final_text,
        crop_results,
        detection_time,
        total_recognition_time,
        html_path,
        json_path,
    ) = process_full_image(local_path, opt, CROPS_DIR)
    total_duration = time.time() - start

    reply = (
        f"üìú –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{final_text}\n\n"
        f"‚è± –í—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_time:.2f} —Å–µ–∫\n"
        f"‚è± –°—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {total_recognition_time*1000:.2f} –º—Å\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_duration:.2f} —Å–µ–∫"
    )
    print(f"[DEBUG] –û—Ç–≤–µ—Ç: {reply}")
    await update.message.reply_text(reply)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º HTML-–æ—Ç—á—ë—Ç –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
    with open(html_path, "rb") as html_file:
        await update.message.reply_document(document=html_file, filename="results.html")
    print("[DEBUG] HTML-–æ—Ç—á—ë—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º JSON —Å COCO-—Ä–∞–∑–º–µ—Ç–∫–æ–π –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
    with open(json_path, "rb") as json_file:
        await update.message.reply_document(document=json_file, filename="results.json")
    print("[DEBUG] JSON —Ä–∞–∑–º–µ—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.")


# ==== –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ====
async def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.Document.IMAGE, handle_document))
    print("[DEBUG] –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω, –æ–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–π...")
    await app.run_polling(close_loop=False)


if __name__ == "__main__":
    asyncio.run(main())
