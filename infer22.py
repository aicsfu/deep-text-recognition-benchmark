import os
import time
import base64
import mimetypes
import pandas as pd
from PIL import Image
import torch
from model import Model
from utils import CTCLabelConverter, AttnLabelConverter
from dataset import AlignCollate

# –í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU –∏–ª–∏ CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# üîß –ù–ê–°–¢–†–û–ô–ö–ò
base_dir = r"C:\A\a2"
image_folder = os.path.join(base_dir, "images")
saved_model = r"C:\best_accuracy.pth"
csv_path = os.path.join(base_dir, "marking.csv")  # CSV —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π

Transformation = "TPS"
FeatureExtraction = "ResNet"
SequenceModeling = "BiLSTM"
Prediction = "Attn"

character = " !%'()*+,-./0123456789:;<=>[]^_v{|}~¬ß¬´¬ª–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—ñ—£—≥—µ‚Ññ"
batch_max_length = 25
imgH = 128
imgW = 512
input_channel = 1
output_channel = 512
hidden_size = 256
rgb = False
PAD = True


# ==== –ö–û–ù–§–ò–ì ====
class Opt:
    pass


opt = Opt()
opt.Transformation = Transformation
opt.FeatureExtraction = FeatureExtraction
opt.SequenceModeling = SequenceModeling
opt.Prediction = Prediction
opt.character = character
opt.batch_max_length = batch_max_length
opt.imgH = imgH
opt.imgW = imgW
opt.input_channel = 3 if rgb else 1
opt.output_channel = output_channel
opt.hidden_size = hidden_size
opt.saved_model = saved_model
opt.rgb = rgb
opt.PAD = PAD
opt.num_fiducial = 20
opt.num_class = len(character)
opt.sensitive = False
opt.data_filtering_off = True


def load_model(opt):
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏
    if "CTC" in opt.Prediction:
        converter = CTCLabelConverter(opt.character)
    else:
        converter = AttnLabelConverter(opt.character)
    opt.num_class = len(converter.character)

    model = Model(opt)
    model = torch.nn.DataParallel(model).to(device)

    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {opt.saved_model}")
    state_dict = torch.load(opt.saved_model, map_location=device)
    if "module" in list(state_dict.keys())[0]:
        model.load_state_dict(state_dict)
    else:
        model.load_state_dict({"module." + k: v for k, v in state_dict.items()})

    model = model.module
    model.eval()
    return model, converter


def preprocess_image(image_path, opt):
    """–û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä"""
    img = Image.open(image_path).convert("RGB" if opt.rgb else "L")
    AlignCollate_infer = AlignCollate(
        imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD
    )
    image_tensor, _ = AlignCollate_infer([(img, "")])
    return image_tensor.to(device)


def predict(model, converter, image, opt):
    """–ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    batch_size = image.size(0)
    length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)
    text_for_pred = (
        torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)
    )

    with torch.no_grad():
        if "CTC" in opt.Prediction:
            preds = model(image, text_for_pred)
            preds_size = torch.IntTensor([preds.size(1)] * batch_size)
            _, preds_index = preds.max(2)
            preds_str = converter.decode(preds_index, preds_size)
        else:
            preds = model(image, text_for_pred, is_train=False)
            _, preds_index = preds.max(2)
            preds_str = converter.decode(preds_index, length_for_pred)
            preds_str = [s.split("[s]")[0] for s in preds_str]

    return preds_str[0]


def image_to_base64_html(image_path, max_width=200):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É HTML —Å —Ç–µ–≥–æ–º <img> (–≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ —á–µ—Ä–µ–∑ base64)."""
    if not os.path.exists(image_path):
        return ""
    with open(image_path, "rb") as img_file:
        img_data = img_file.read()
    mime_type, _ = mimetypes.guess_type(image_path)
    if mime_type is None:
        mime_type = "image/png"
    b64_data = base64.b64encode(img_data).decode("utf-8")
    return f'<img src="data:{mime_type};base64,{b64_data}" style="max-width: {max_width}px;"/>'


def process_csv_predictions(opt, csv_path, base_dir):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π
    df_mark = pd.read_csv(csv_path).iloc[:1000]
    results = []

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑
    model, converter = load_model(opt)

    total = len(df_mark)
    print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {total} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ CSV...\n")
    for idx, row in df_mark.iterrows():
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        rel_path = row["path"].replace("/", os.sep).replace("\\", os.sep)
        image_path = (
            os.path.join(base_dir, rel_path)
            if not os.path.isabs(rel_path)
            else rel_path
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(image_path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
            pred = ""
            thumb = ""
        else:
            image_tensor = preprocess_image(image_path, opt)
            start_time = time.time()
            pred = predict(model, converter, image_tensor, opt)
            end_time = time.time()
            duration = (end_time - start_time) * 1000
            print(
                f"{os.path.basename(image_path):<30} ‚Üí {pred:<30} ({duration:.2f} ms)"
            )
            # –°–æ–∑–¥–∞–µ–º HTML-–º–∏–Ω–∏–∞—Ç—é—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            thumb = image_to_base64_html(image_path, max_width=100)

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∏—Å—Ç–∏–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–Ω–æ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É)
        truth = str(row["text"]).strip()
        prediction = pred.strip() if pred else ""
        # –ï—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–∞–ª–∏—Ç–µ .lower()
        correct = truth.lower() == prediction.lower()

        results.append(
            {
                "correct": correct,
                "path": image_path,
                "truth": truth,
                "prediction": prediction,
                "thumbnail": thumb,
            }
        )

    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    df_results = pd.DataFrame(results)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ)
    results_csv = os.path.join(base_dir, "results.csv")
    df_results.to_csv(results_csv, index=False, encoding="utf-8-sig")
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {results_csv}")

    # –î–ª—è HTML-—Ç–∞–±–ª–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–∞—Ç—é—Ä—É –≤–º–µ—Å—Ç–æ –ø—É—Ç–∏
    # –£–ø–æ—Ä—è–¥–æ—á–∏–º —Å—Ç–æ–ª–±—Ü—ã –ø–æ: –º–∏–Ω–∏–∞—Ç—é—Ä–∞, –∏—Å—Ç–∏–Ω–∞, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
    df_html = df_results[["thumbnail", "truth", "prediction", "correct"]]
    results_html = os.path.join(base_dir, "results.html")
    with open(results_html, "w", encoding="utf-8") as f:
        f.write(df_html.to_html(escape=False, index=False))
    print(f"üåê –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ HTML: {results_html}")


# üöÄ –°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
if __name__ == "__main__":
    process_csv_predictions(opt, csv_path, base_dir)
