import os
import time
from PIL import Image
import torch

from dataset import AlignCollate  # ‚ö†Ô∏è –£–∂–µ —É —Ç–µ–±—è –µ—Å—Ç—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==== üîß –ö–û–ù–§–ò–ì ====
config = {
    "image_path": r"C:\A\a2\images",  # –ü—É—Ç—å –¥–æ –ø–∞–ø–∫–∏ –∏–ª–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    "torchscript_model_path": "frozen_model.pt",
    "imgH": 128,
    "imgW": 512,
    "input_channel": 1,
    "batch_max_length": 25,
    "rgb": False,
    "character": " !%'()*+,-./0123456789:;<=>[]^_v{|}~¬ß¬´¬ª–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—ñ—£—≥—µ‚Ññ",
}


# ==== üì¶ –ó–ê–ì–†–£–ó–ö–ê TorchScript-–ú–û–î–ï–õ–ò ====
model = torch.jit.load(config["torchscript_model_path"], map_location=device)
model.eval()


# ==== üì∑ –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì –° ALIGNCOLLATE ====
def preprocess_image_aligncollate(image_path, config):
    img = Image.open(image_path).convert("RGB" if config["rgb"] else "L")
    align = AlignCollate(
        imgH=config["imgH"], imgW=config["imgW"], keep_ratio_with_pad=True
    )
    image_tensor, _ = align([(img, "")])
    return image_tensor.to(device)


# ==== üß† –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï ====
def predict(image_tensor, config):
    batch_size = image_tensor.size(0)
    text_input = torch.zeros(
        batch_size, config["batch_max_length"] + 1, dtype=torch.long
    ).to(device)

    with torch.no_grad():
        output = model(image_tensor, text_input)  # Attn

    _, pred_index = output.max(2)
    pred_index = pred_index.squeeze(0).tolist()

    # –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É
    char_list = list(config["character"])
    char_list.insert(0, "[GO]")
    char_list.append("[s]")

    pred_str = ""
    for idx in pred_index:
        char = char_list[idx]
        if char == "[s]":
            break
        pred_str += char

    return pred_str


# ==== üöÄ –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====
def run_inference(config):
    image_path = config["image_path"]
    if os.path.isdir(image_path):
        image_files = sorted(
            [
                os.path.join(image_path, f)
                for f in os.listdir(image_path)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]
        )
    else:
        image_files = [image_path]

    if not image_files:
        print("‚ùå –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    total_time = 0
    print(f"\nüîç –†–∞—Å–ø–æ–∑–Ω–∞—ë–º {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n")

    for img_path in image_files:
        image_tensor = preprocess_image_aligncollate(img_path, config)

        start = time.time()
        pred = predict(image_tensor, config)
        end = time.time()

        duration = end - start
        total_time += duration

        print(
            f"{os.path.basename(img_path):<30} ‚Üí {pred:<30} ({duration * 1000:.2f} ms)"
        )

    avg = total_time / len(image_files)
    print("\n" + "=" * 60)
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {avg * 1000:.2f} ms")
    print("=" * 60)


# ==== üî• –°–¢–ê–†–¢ ====
if __name__ == "__main__":
    run_inference(config)
